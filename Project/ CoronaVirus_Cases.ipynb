{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOpXK/e3Z9ugMiZzj7trkh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudycav/Web-Scraping-CoronaVirus-Cases/blob/master/Project/%20CoronaVirus_Cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4m9LczMP-dV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "def webscrape(url = 'https://www.worldometers.info/coronavirus/'):\n",
        "  header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}\n",
        "  link = requests.get(url, header)\n",
        "  bs = BeautifulSoup(link.content,'lxml')\n",
        "  title_numbers = bs.find_all(['h1','span'])\n",
        "  numbers = bs.find_all(class_='maincounter-number')\n",
        "  data_table = bs.find_all('table', class_='main_table_countries')\n",
        "   \n",
        "  data = []\n",
        "\n",
        "  for table in data_table:\n",
        "      headers = []\n",
        "      rows = table.find_all('tr')\n",
        "      for header in table.find('tr').find_all('th'):\n",
        "          headers.append(header.text)\n",
        "      for row in table.find_all('tr')[1:]:\n",
        "          values = []\n",
        "          for column in row.find_all(['th', 'td']):\n",
        "              values.append(column.text)\n",
        "          if values:\n",
        "              dt = {headers[i]: values[i] for i in range(len(values))}\n",
        "              data.append(dt)\n",
        "              \n",
        "  df = pd.DataFrame(data).rename(columns={\"1stcase\": \"FirstCase\", \"Serious,Critical\": \"Critical\"})\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = webscrape()\n",
        "\n",
        "def punctuation_removal(df):\n",
        "    try:\n",
        "        #removes N/A, commas, and + symbol, converts empty cells into 0s from the dataframe\n",
        "        df = df.str.replace('N/A','').str.replace(',','').replace(r'^\\s*$', np.nan, regex=True).replace(np.nan, 0).astype(float).astype(int)\n",
        "    except:\n",
        "        pass\n",
        "    return df\n",
        "\n",
        "df = df.apply(punctuation_removal)\n"
      ],
      "metadata": {
        "id": "OYcB9ry52gWV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove newline in Country column\n",
        "df['Country,Other'] = df['Country,Other'].replace(r'\\n',' ', regex=True) "
      ],
      "metadata": {
        "id": "uhU2kTh7GQhO"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}